{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 231 Machine Learning: Homework 4, part 2** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Fully-connected deep neural networks**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Emilio, Simon** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 21/5** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Name, Personal no., email** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical and practical problems should be submitted in this Jupyter notebook.\n",
    "* All discussion regarding practical problems, along with solutions and plots should be specified in this notebook. All plots/results should be visible such that the notebook do not have to be run. But the code in the notebook should reproduce the plots/results if we choose to do so.  \n",
    "* Your name, personal number and email address should be specified above.\n",
    "\n",
    "**Jupyter/IPython Notebook** is a collaborative Python web-based environment. This will be used in all our Homework Assignments. It is installed in the halls ES61-ES62, E-studio and MT9. You can also use google-colab: https://colab.research.google.com\n",
    "to run these notebooks without having to download, install, or do anything on your own computer other than a browser.\n",
    "Some useful resources:\n",
    "\n",
    "1. https://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/ (Quick-start guide)\n",
    "2. https://www.kdnuggets.com/2016/04/top-10-ipython-nb-tutorials.html\n",
    "3. http://data-blog.udacity.com/posts/2016/10/latex-primer/ (latex-primer)\n",
    "4. http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html (markdown)\n",
    "\n",
    "In this assignment you will be using the `pytorch` package. Installation instructions can be found on the [pytorch homepage](https://pytorch.org/get-started/locally/). You don't need the GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Calculating dimensions of output for CNN, 1 point]\n",
    "### 1)\n",
    "Assume you apply a convolutional layer with 8 3x3 filters (stride 1) on a rgb 28x13 image. What will the dimensions of the output be (assuming no padding is done in the convolution)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Counting parameters in a fully connected network, 1 point]\n",
    "### 2)\n",
    "Imagine you apply a two layer fully connected network to a 28x28 rgb image. The hidden layer has dimension 256 and the output is of size 10. How many parameters are necessary? Include the bias parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Counting parameters in a convolutional network, 1 point]\n",
    "### 3)\n",
    "Apply the following network to the same image, how many parameters are needed? Include bias parameters. Show your calculations.\n",
    "\n",
    "* Convolutional layer with 8 3x3 filters.\n",
    "\n",
    "* Max pooling layer (2x2)\n",
    "\n",
    "* Convolutional layer with 16 3x3 filter \n",
    "\n",
    "* Fully connected layer to ouput of size 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the amount of parameters for a CNN can be a lot less than for a fully connected network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Applying a filter, 2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image\n",
    "$\n",
    "\\begin{bmatrix}2 & 2 & 1 & 2 \\\\\n",
    "               -2 & -2 & -1 & 1 \\\\\n",
    "               1 & 1 & 2 & 1 \\\\\n",
    "               1 & 1 & 3 & 1 \n",
    "\\end{bmatrix}$\n",
    "Filter \n",
    "$\n",
    "\\begin{bmatrix}1 & 1\n",
    "\\\\-1 & -1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Convolve the filter over the image and apply ReLU, use a stride of 2 with a bias of -2. Try to give an explanation for the output, what is the filter detecting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:$\n",
    "\\begin{bmatrix} \n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Gradients in CNN, 2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply a 2x2 filter (with weights $W$) on a 2x$n$ greyscale image $x$ generating a 1x($n$-1) sequence $z$.\n",
    "\n",
    "We then get \n",
    "$$ \n",
    "\\text{Filter}: \\, \\left[ \\begin{array}{ccc} \n",
    "W_{1,1} & W_{1,2}\\\\\n",
    "W_{2,1} & W_{2,2}\\\\\n",
    "\\end{array}\\right]\n",
    " \\text{Image}: \\, \\left[ \\begin{array}{ccc} \n",
    "x_{1,1} & x_{1,2}  & ... & x_{1,n}\\\\\n",
    "x_{2,1} & x_{2,2}  & ... & x_{2,n} \\\\\n",
    "\\end{array}\\right]\n",
    " \\text{Output}: \\, \\left[ \\begin{array}{ccc} \n",
    "z_{1} & z_{2}  & ... & z_{n-1}\\\\\n",
    "\\end{array}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, a)\n",
    "Write $z_i$ as a function of $W$ and $x$.\n",
    "$$\n",
    "\\begin{align}\n",
    "z_i = \\: ? \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, b)\n",
    "Lets assume we know $\\frac{dE}{dz_i}$. Calculate the gradient of the error with respect to the filter and the image. You can ignore the edge cases by assuming $x_{i,j}=0$ for i outside the image and similary for $z_i$. \n",
    "\\begin{align}\n",
    "\\frac{dE}{dW_{i,j}}= \\: ? \\\\\n",
    "\\frac{dE}{dx_{i,j}}= \\: ? \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Building a CNN with pytorch, 3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "Build a convolutional network from the following specification:\n",
    "* Input is a single channel image (black/white).\n",
    "* Conv1  has 8 3x3 filters with ReLU activation\n",
    "* Max pooling (2x2) layer\n",
    "* Conv2  has 16 3x3 filters with ReLU activation\n",
    "* Reshape data for fully connected layer\n",
    "* Three fully connected layers that will have hidden dimensions 32 and 64.\n",
    "    * The first two layers have ReLU activation while the final layer doesn't have any.\n",
    "\n",
    "You will have to figure out some of the implicit dimensions of the different layers and all necessary methods are already imported. You can use tensor.view() to change shape of a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Linear\n",
    "from torch.functional import relu, max_pool2d, log_softmax\n",
    "\n",
    "\n",
    "\n",
    "class MyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyConvNet self).__init__()\n",
    "        self.conv1 = #?\n",
    "        self.conv2 = #?\n",
    "        self.fc1   = #?\n",
    "        self.fc2   = #?\n",
    "        self.fc3   = #?\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Fill in here\n",
    "        out = self.fc3(out)\n",
    "return log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "training_data = datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
    "\n",
    "n = len(training_data)\n",
    "n_train = int(0.9 * n)\n",
    "n_val = n - n_train\n",
    "training_data, validation_data = random_split(training_data, [n_train, n_val])\n",
    "training_loader   = DataLoader(training_data, batch_size = 64, shuffle = True)\n",
    "validation_loader = DataLoader(validation_data, batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add optimizer and initialize model\n",
    "import torch\n",
    "model = MyConvNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train network:\n",
    "import torch.nn.functional as F\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for (data, target) in training_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well does the network perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_error(model):\n",
    "    \"\"\"\n",
    "    Compute the validation error of the given model in percent.\n",
    "    \"\"\"\n",
    "    error = 0.0\n",
    "    for (data, target) in validation_loader:\n",
    "        error += torch.sum(model(data).argmax(dim = 1) != target).float()\n",
    "    error /= float(len(validation_data))\n",
    "    return 100.0 * error\n",
    "    \n",
    "print(\"Validation error: {0:.2f}%.\".format(validation_error(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [A better classifier, 2 points]\n",
    "Compare with http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354\n",
    "\n",
    "Make changes to get a validation error lower than 1.5%. \n",
    "you are allowed (and even encouraged) to use all other available features\n",
    "from the `pytorch` library.\n",
    "Helpful `pytorch` sub-modules are the [nn](https://pytorch.org/docs/stable/nn.html) module and the [optmizers](https://pytorch.org/docs/stable/optim.html) module. \n",
    "\n",
    "Some suggestions on things to try out are:\n",
    "* size of layers\n",
    "* number of layers\n",
    "* learning rate\n",
    "* different optimizer\n",
    "* number of epochs\n",
    "\n",
    "Feel free to be creative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Linear, Module\n",
    "from torch.nn.functional import relu, max_pool2d, log_softmax\n",
    "\n",
    "\n",
    "\n",
    "class MyImprovedConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyImprovedConvNet, self).__init__()\n",
    "        #Fill in here\n",
    "    def forward(self, x):\n",
    "        #Fill in here\n",
    "        out = self.fc3(out)\n",
    "return log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "import torch\n",
    "model = MyImprovedConvNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train:\n",
    "import torch.nn.functional as F\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for (data, target) in training_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
